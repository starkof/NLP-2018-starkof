{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries.\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function allows one to open a given pickle file and use a model that has been stored in it.\n",
    "def load(file):\n",
    "    with open(file,'rb') as f:\n",
    "        trainedData = pickle.load(f)\n",
    "    return trainedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function takes a given amount of files and splits them into training and testing data.\n",
    "#It uses pandas librabry to read, and join the data together as one.\n",
    "#It also uses sklearn's Tfidf vectorizer to turn the data into an array of features.\n",
    "#The vectorizer is saved in a pickle file to enable easy reference instead of constant preprocessiong after every run.\n",
    "#The training and test data are then returned.\n",
    "def preProcessing(*files):\n",
    "    dataList = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file, sep=\"\\t\", header = None)\n",
    "        dataList.append(df)\n",
    "    frame = pd.concat(dataList)\n",
    "    X = frame[0]\n",
    "    y = frame[1]\n",
    "    normal = TfidfVectorizer(use_idf= True, lowercase = True, strip_accents = ascii, stop_words=set(stopwords.words('english')))\n",
    "    cleanX = normal.fit_transform(X)\n",
    "    with open(\"vectorizer4.pickle\",'wb') as f:\n",
    "        pickle.dump(normal, f)\n",
    "    featureArr = cleanX.toarray()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(featureArr, y, test_size = 0.2, random_state = 0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "#This function takes a given amount of files to be classified.\n",
    "#It uses pandas librabry to read, and join the data together as one.\n",
    "#It also uses sklearn's Tfidf vectorizer to turn the data into an array of features.\n",
    "#The vectorizer is saved in a pickle file to enable easy reference instead of constant preprocessiong after every run.\n",
    "#The training and test data are then returned. \n",
    "def toVector(*files):\n",
    "    dataList = []\n",
    "    \n",
    "    for file in files:\n",
    "        df = pd.read_table(file, header = None)\n",
    "        dataList.append(df)\n",
    "        \n",
    "    frame = pd.concat(dataList)\n",
    "    \n",
    "    vectorizer = load('vectorizer4.pickle')\n",
    "    features = vectorizer.transform(frame[0])\n",
    "    featureArr = features.toarray()\n",
    "    return featureArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function creates a naive bayes model and trains on x_train and y_train.\n",
    "#The trained model is stored in a pickle file.\n",
    "def naiveBayes(tup):\n",
    "    nb = MultinomialNB()\n",
    "    nb.fit(tup[0], tup[2])\n",
    "    with open(\"bayes2.pickle\",'wb') as f:\n",
    "        pickle.dump(nb, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#This function supplies data to be trained on to the preProcessing fuction \n",
    "#It also runs the naiveBayes function above on the results of the preProcessing function.\n",
    "def train():\n",
    "    values = preProcessing('amazon_cells_labelled.txt','yelp_labelled.txt','imdb_labelled.txt')\n",
    "    naiveBayes(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This function allows command line interface by taking the argument variables parameter.\n",
    "#It vectorizes the data to be classified (argv[3]).\n",
    "#It then checks if the model has been saved in a pickle file, if it is, it loads its contents and calls the predict method on the \n",
    "#given file. If it hasn't been saved, the model is trained and the pickle file generated from training is used in predicting.\n",
    "#It then writes the preidcted content to a .txt file\n",
    "def main(argv):\n",
    "    testData = toVector(argv[3])\n",
    "    writeFile = open('nb-n.txt', 'w')\n",
    "    exist = False\n",
    "    try:\n",
    "        f = open('bayes2.pickle', 'rb')\n",
    "        f.close()\n",
    "        exist = True\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "    if exist is True:\n",
    "        model = load('bayes2.pickle')\n",
    "        pred = model.predict(testData)\n",
    "        pred = pred.tolist()\n",
    "        for i in pred:\n",
    "            writeFile.write(str(i)+'\\n')\n",
    "    else:\n",
    "        train()\n",
    "        model = load('bayes2.pickle')\n",
    "        pred = model.predict(testData)\n",
    "        pred = pred.tolist()\n",
    "        for i in pred:\n",
    "            writeFile.write(str(i)+'\\n')\n",
    "main(sys.argv) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if __name__ == 'main':\n",
    "    main(argv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
