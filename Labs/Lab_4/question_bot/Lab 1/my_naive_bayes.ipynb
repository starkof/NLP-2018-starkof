{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing necessary libraries and opening text files\n",
    "import math as m\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "readFile1 =  open('amazon_cells_labelled.txt', 'r')\n",
    "readFile2 =  open('imdb_labelled.txt', 'r')\n",
    "readFile3 =  open('yelp_labelled.txt', 'r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The Data Handler class is responsible for the training and testing of the Naive Bayes Classifier.\n",
    "It takes .txt files and trains on 80 percent of the data in the file.\n",
    "From this, it calculates likelihoods of a given word in a certain class and probabilities of the occurence of a class.\n",
    "The remaining 20 percent of the data will be used for testing.\n",
    "Creating an instance of this class calculates log(likelihoods) for each word given a specific class and stores it in a\n",
    "hashmap for referencing.\n",
    "'''\n",
    "class DataHandler():\n",
    "    \n",
    "    #Initializing constructor of the data handler class\n",
    "    def __init__(self,*files):\n",
    "        self.files= files\n",
    "        self.trainingData , self.testData = self.splitToData()\n",
    "        self.negative, self.positive, self.classes, self.freqLookup = self.splitToBags()\n",
    "        self.vocabulary = self.createVocabulary()\n",
    "        self.priors = self.calculateLogPriors()\n",
    "        self.logLikelihoods = self.calculateLogLikelihoods()\n",
    "        self.test = self.test()\n",
    "        self.accuracy = self.testAccuracy()\n",
    "        self.summary = self.printSummary()\n",
    "        \n",
    "\n",
    "    #Function to split into training and test data\n",
    "    def splitToData(self):\n",
    "        data =[]\n",
    "        for file in self.files:\n",
    "            for line in file:\n",
    "                cleanLine = line.rstrip('\\n').split('\\t')\n",
    "                sentence = cleanLine[0].replace(\".\",\"\").replace(\"!\",\"\").replace(\"-\",\"\").replace(\":\",\"\").replace(\")\",\"\").replace(\";\",\"\").replace(\"@\",\"\").replace(\"(\",\"\").replace(\",\",\"\").replace(\"&\",\"\").replace('\"','').replace(\"?\",\"\").replace(\"*\",\"\").replace(\"+\",\"\").lower()\n",
    "                features = sentence.split(' ')\n",
    "                tag = cleanLine[1]\n",
    "                pair = (features,tag)\n",
    "                data.append(pair)\n",
    "        file.close()\n",
    "        random.shuffle(data)\n",
    "        trainingData= data[0:int(0.8*len(data))]\n",
    "        testData = data[int(0.8*len(data)):]\n",
    "        return(trainingData, testData)\n",
    "\n",
    "   # Function to split training data into positive and negative bags of words and a list to keep all classes.\n",
    "   # Here, the frequencies of each word in each class is calculated and stored in a dictionary.\n",
    "\n",
    "    def splitToBags(self):\n",
    "        positive =[]\n",
    "        negative =[]\n",
    "        classes = []\n",
    "        freqLookup ={}\n",
    "        for doc in self.trainingData:\n",
    "            classes.append(doc[1])\n",
    "            if doc[1]== '1':\n",
    "                for word in doc[0]:\n",
    "                    if (word.lower(),1) not in freqLookup:\n",
    "                        freqLookup[(word.lower(),1)] = 1\n",
    "                    else:\n",
    "                        freqLookup[(word.lower(),1)]+= 1 \n",
    "                    positive.append(word.lower())\n",
    "                    if (word.lower(),0) not in freqLookup:\n",
    "                        freqLookup[(word.lower(),0)] = 0\n",
    "            elif doc[1]== '0':\n",
    "                for word in doc[0]:\n",
    "                    if (word,0) not in freqLookup:\n",
    "                        freqLookup[(word.lower(),0)] = 1\n",
    "                    else:\n",
    "                        freqLookup[(word.lower(),0)]+= 1\n",
    "                    if (word.lower(),1) not in freqLookup:\n",
    "                        freqLookup[(word.lower(),1)] = 0\n",
    "                    negative.append(word.lower())\n",
    "        return(negative,positive,classes,freqLookup)\n",
    "\n",
    "    #Fuction that loops through positive and negative words to create vocabulary of unique words\n",
    "    def createVocabulary(self):\n",
    "        vocabulary =[]\n",
    "        for word in self.negative:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "        for word in self.positive:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary.append(word)\n",
    "        return vocabulary\n",
    "\n",
    "    # Function to calculate for the prior probability of the classes\n",
    "    def calculateLogPriors(self):\n",
    "        negClass =[]\n",
    "        priors = {}\n",
    "        for i in self.classes:\n",
    "            if i == '0':\n",
    "                negClass.append(1)\n",
    "        negProb = sum(negClass)/len(self.classes)\n",
    "        posProb = 1-negProb\n",
    "        negPrior = m.log10(negProb)\n",
    "        posPrior = m.log10(posProb)\n",
    "        priors['0'] = negPrior\n",
    "        priors['1'] = posPrior\n",
    "        return priors\n",
    "    \n",
    "    #Function to find likelihood of a word\n",
    "    def calculateLogLikelihoods(self):\n",
    "        likelihoodLookup ={}\n",
    "        posDenominator =[]\n",
    "        negDenominator =[]\n",
    "        for word in self.vocabulary:\n",
    "            posDenominator.append(self.freqLookup[(word,1)]+1)\n",
    "            negDenominator.append(self.freqLookup[(word,0)]+1)\n",
    "        for word in self.vocabulary:\n",
    "            posLikelihood = m.log10((self.freqLookup[(word,1)]+1)/sum(posDenominator))\n",
    "            likelihoodLookup[(word,1)] = posLikelihood\n",
    "            negLikelihood = m.log10((self.freqLookup[(word,0)]+1)/sum(negDenominator))\n",
    "            likelihoodLookup[(word,0)] = negLikelihood\n",
    "        return likelihoodLookup\n",
    "    \n",
    "    #Function to test data\n",
    "    def test(self):\n",
    "        result = {}\n",
    "        summary =[]\n",
    "        for testDoc in self.testData:\n",
    "            testSentence = (' ').join(testDoc[0])\n",
    "            sumPosLikelihood = self.priors['1']\n",
    "            sumNegLikelihood = self.priors['0']\n",
    "            for i in testDoc[0]:\n",
    "                if i in self.vocabulary:\n",
    "                    sumPosLikelihood+= self.logLikelihoods[(i,1)]\n",
    "                    sumNegLikelihood+= self.logLikelihoods[(i,0)]\n",
    "                else:\n",
    "                    sumPosLikelihood+= 0\n",
    "                    sumNegLikelihood+= 0\n",
    "            result['0'] = sumNegLikelihood\n",
    "            result['1'] = sumPosLikelihood\n",
    "            if result['0']>result['1']:\n",
    "                summary.append((testSentence,'0'))\n",
    "            else:\n",
    "                summary.append((testSentence,'1'))\n",
    "        return summary\n",
    "    \n",
    "    #Calulating accuracy\n",
    "    def testAccuracy(self):\n",
    "        correct = []\n",
    "        for i in range (len(self.test)):\n",
    "            if self.test[i][1]== self.testData[i][1]:\n",
    "                correct.append(1)\n",
    "            else:\n",
    "                pass\n",
    "        return(round((sum(correct)/len(self.test))*100,2))\n",
    "    \n",
    "    #Printing data handler summary\n",
    "    def printSummary(self):\n",
    "        print(\"--------------------------\")\n",
    "        print(\"Length of training data: \", len(self.trainingData))\n",
    "        print(\"Length of test data: \", len(self.testData))\n",
    "        print(\"Words in positive bag: \", len(self.positive))\n",
    "        print(\"Words in negative bag: \", len(self.negative))\n",
    "        print(\"Total word count: \", (len(self.positive)+len(self.negative)))\n",
    "        print(\"Unique words in vocabulary: \", len(self.vocabulary))\n",
    "        print(\"Log(prob) of negative class: \", self.priors['0'])\n",
    "        print(\"Log(prob) of positive class:\", self.priors['1'])\n",
    "        print(\"Test Accuracy: \", self.accuracy, \"%\")\n",
    "        print(\"--------------------------\")\n",
    "\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The NaiveBayesClassifier class takes a data handler and a file to classify.\n",
    "An instance of this class runs through the documents in a file and predicts the class they belong to.\n",
    "'''\n",
    "class NaiveBayesClassifier():\n",
    "    def __init__(self,handler,file):\n",
    "        self.handler = handler\n",
    "        self.file = open(str(file),'r')\n",
    "        self.data = self.splitToData()\n",
    "        self.classify = self.classify()\n",
    "        \n",
    "    def splitToData(self):\n",
    "        data =[]\n",
    "        for line in self.file:\n",
    "            cleanLine = line.rstrip('\\n')\n",
    "            sentence = cleanLine.replace(\".\",\"\").replace(\"!\",\"\").replace(\"-\",\"\").replace(\":\",\"\").replace(\")\",\"\").replace(\";\",\"\").replace(\"@\",\"\").replace(\"(\",\"\").replace(\",\",\"\").replace(\"&\",\"\").replace('\"','').replace(\"?\",\"\").replace(\"*\",\"\").replace(\"+\",\"\").lower()\n",
    "            features = sentence.split(' ')\n",
    "            pair = (features)\n",
    "            data.append(pair)\n",
    "        self.file.close()\n",
    "        return data\n",
    "    \n",
    "    def classify(self):\n",
    "        result={}\n",
    "        summary =[]\n",
    "        writeFile = open('results.txt','w')\n",
    "        for testDoc in self.data:\n",
    "            testSentence = (' ').join(testDoc)\n",
    "            sumPosLikelihood = self.handler.priors['1']\n",
    "            sumNegLikelihood = self.handler.priors['0']\n",
    "            for i in testDoc:\n",
    "                if i in self.handler.vocabulary:\n",
    "                    sumPosLikelihood+= self.handler.logLikelihoods[(i,1)]\n",
    "                    sumNegLikelihood+= self.handler.logLikelihoods[(i,0)]\n",
    "            result['0'] = sumNegLikelihood\n",
    "            result['1'] = sumPosLikelihood\n",
    "            if result['0']>result['1']:\n",
    "                summary.append(('0'))\n",
    "            else:\n",
    "                summary.append(('1'))\n",
    "        for i in summary:\n",
    "            writeFile.write(i+'\\n')\n",
    "        writeFile.close()\n",
    "        return summary\n",
    "            \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Testing Naive Bayes Classifier\n",
    "def main(argv):\n",
    "    start = time.time()\n",
    "    handler = DataHandler(readFile1,readFile2,readFile3)\n",
    "    classifier = NaiveBayesClassifier(handler,argv[1])\n",
    "    end = time.time()\n",
    "    print(\"Completed in \"+str(round((end-start),2))+' seconds')\n",
    "    \n",
    "main(sys.argv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
